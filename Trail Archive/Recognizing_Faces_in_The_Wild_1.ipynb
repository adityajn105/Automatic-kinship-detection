{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-length",
         "5492"
        ],
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "HT0HhLIAEKeP",
    "outputId": "6b2db2d4-3dcd-46fe-841f-e460e63a592b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a263b7c8-5163-4450-862d-6e75b6b02ae1\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-a263b7c8-5163-4450-862d-6e75b6b02ae1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"adityajn105\",\"key\":\"571939f74e6a6e23ec01a7d769da7958\"}'}"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "5poCvtK_EPGB",
    "outputId": "9d7bddc1-8e64-4b99-c77f-3f5408149b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading train_relationships.csv to /content\n",
      "\r",
      "  0% 0.00/77.6k [00:00<?, ?B/s]\n",
      "\r",
      "100% 77.6k/77.6k [00:00<00:00, 31.0MB/s]\n",
      "Downloading test.zip to /content\n",
      "\r",
      "  0% 0.00/34.1M [00:00<?, ?B/s]\r",
      " 15% 5.00M/34.1M [00:00<00:01, 15.9MB/s]\r",
      " 26% 9.00M/34.1M [00:00<00:01, 19.1MB/s]\r",
      " 50% 17.0M/34.1M [00:00<00:00, 21.8MB/s]\n",
      "\r",
      "100% 34.1M/34.1M [00:00<00:00, 43.8MB/s]\n",
      "Downloading train.zip to /content\n",
      " 92% 63.0M/68.6M [00:01<00:00, 19.9MB/s]\n",
      "100% 68.6M/68.6M [00:01<00:00, 38.4MB/s]\n",
      "Downloading sample_submission.csv to /content\n",
      "  0% 0.00/156k [00:00<?, ?B/s]\n",
      "100% 156k/156k [00:00<00:00, 162MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir /root/.kaggle\n",
    "!mv kaggle.json /root/.kaggle/\n",
    "!kaggle competitions download -c recognizing-faces-in-the-wild\n",
    "!mkdir train test\n",
    "!unzip -q train.zip -d train\n",
    "!unzip -q test.zip -d test\n",
    "!rm train.zip test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tK-nGulEo__R"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6MxrfTqork91",
    "outputId": "1419c223-eb2c-4335-ec9f-c98076ba576f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "from keras_vggface.utils import preprocess_input\n",
    "\n",
    "IMG_DIM = (224,224,3)\n",
    "\n",
    "def read_img(path):\n",
    "  return preprocess_input( img_to_array( load_img(path, target_size=IMG_DIM) ),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "psjuVfOyXZea"
   },
   "outputs": [],
   "source": [
    "allPhotos = dict()\n",
    "for family in glob.glob(\"train/*\"):\n",
    "  for mem in glob.glob(family+'/*'):\n",
    "    allPhotos[mem] = []\n",
    "    for photo in glob.glob(mem+'/*'):\n",
    "      allPhotos[mem].append(read_img(photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "MdMCkPo7oBM8",
    "outputId": "f84038a0-6f21-4aa8-c9ab-e0448ddd440a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3598, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/F0002/MID1</td>\n",
       "      <td>train/F0002/MID3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/F0002/MID2</td>\n",
       "      <td>train/F0002/MID3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/F0005/MID1</td>\n",
       "      <td>train/F0005/MID2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/F0005/MID3</td>\n",
       "      <td>train/F0005/MID2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/F0009/MID1</td>\n",
       "      <td>train/F0009/MID4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 p1                p2  related\n",
       "0  train/F0002/MID1  train/F0002/MID3        1\n",
       "1  train/F0002/MID2  train/F0002/MID3        1\n",
       "2  train/F0005/MID1  train/F0005/MID2        1\n",
       "3  train/F0005/MID3  train/F0005/MID2        1\n",
       "4  train/F0009/MID1  train/F0009/MID4        1"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('train_relationships.csv')\n",
    "data.p1 = data.p1.apply( lambda x: 'train/'+x )\n",
    "data.p2 = data.p2.apply( lambda x: 'train/'+x )\n",
    "data['related'] = 1 \n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9FqKCjLSsD9J"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "families = glob.glob('train/*')\n",
    "p1 = []; p2 = []\n",
    "for f1,f2 in combinations(families,2) :\n",
    "  for _p1 in glob.glob( '{}/*'.format(f1) ):\n",
    "    for _p2 in glob.glob( '{}/*'.format(f2) ):\n",
    "      p1.append( _p1 ); p2.append( _p2 );\n",
    "temp = pd.DataFrame({'p1':p1,'p2':p2,'related':np.zeros( (len(p1),) ,dtype=np.int32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "MUlh6iQusuCy",
    "outputId": "227492ee-b5f1-46ff-ffa5-d5fe3228ce36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10794, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/F0030/MID3</td>\n",
       "      <td>train/F0438/MID2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/F0130/MID3</td>\n",
       "      <td>train/F0130/MID1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/F0812/MID1</td>\n",
       "      <td>train/F0831/MID7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/F1000/MID7</td>\n",
       "      <td>train/F0756/MID3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/F0203/MID3</td>\n",
       "      <td>train/F0203/MID5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 p1                p2  related\n",
       "0  train/F0030/MID3  train/F0438/MID2        0\n",
       "1  train/F0130/MID3  train/F0130/MID1        1\n",
       "2  train/F0812/MID1  train/F0831/MID7        0\n",
       "3  train/F1000/MID7  train/F0756/MID3        0\n",
       "4  train/F0203/MID3  train/F0203/MID5        1"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp.sample(n=data.shape[0]*2)\n",
    "data = data.append(temp).sample(frac=1.).reset_index().drop(['index'],axis=1)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ucDz9dmgAX0D",
    "outputId": "5503996d-3108-436b-a059-120487169261"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>related</th>\n",
       "      <th>p1l</th>\n",
       "      <th>p2l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/F0030/MID3</td>\n",
       "      <td>train/F0438/MID2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/F0130/MID3</td>\n",
       "      <td>train/F0130/MID1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/F0812/MID1</td>\n",
       "      <td>train/F0831/MID7</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/F1000/MID7</td>\n",
       "      <td>train/F0756/MID3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/F0203/MID3</td>\n",
       "      <td>train/F0203/MID5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 p1                p2  related  p1l  p2l\n",
       "0  train/F0030/MID3  train/F0438/MID2        0    8   14\n",
       "1  train/F0130/MID3  train/F0130/MID1        1    6   11\n",
       "2  train/F0812/MID1  train/F0831/MID7        0   13    1\n",
       "3  train/F1000/MID7  train/F0756/MID3        0    2    4\n",
       "4  train/F0203/MID3  train/F0203/MID5        1    1    2"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['p1l'] = data.p1.apply( lambda x: len(allPhotos[x]) if x in allPhotos.keys() else 0  )\n",
    "data['p2l'] = data.p2.apply( lambda x: len(allPhotos[x]) if x in allPhotos.keys() else 0 )\n",
    "data = data[ (data.p1l!=0) & (data.p2l!=0) ]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1DMuAgZVElFX",
    "outputId": "7950a944-8115-4625-8435-fee962913a8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del temp, p1, p2; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HK89-Y-K0UwZ",
    "outputId": "da98d0d0-2394-4476-8d44-cd0da85aeb34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7382, 2), (3164, 2), (7382,), (3164,))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val, Y_train, Y_val = train_test_split( data[['p1','p2']], data.related, test_size=0.3, stratify = data.related,  )\n",
    "train.shape,val.shape,Y_train.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jBi9q2Zf7HS5"
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "val.reset_index(inplace=True)\n",
    "Y_train = Y_train.reset_index()\n",
    "Y_val = Y_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "grj2PbcEXlY6"
   },
   "outputs": [],
   "source": [
    "def getImages(p1,p2):\n",
    "    _p1 = allPhotos[p1];_p2 = allPhotos[p2]\n",
    "    return _p1[np.random.randint(len(_p1))], _p2[np.random.randint(len(_p2))]\n",
    "\n",
    "def getMiniBatch(batch_size=32, path = train, y = Y_train):\n",
    "  p1 = []; p2 = []; Y = []\n",
    "  indexes = np.random.choice( path[y==1].index, size=int(batch_size/2), replace=False )\n",
    "  for index in indexes:\n",
    "    _p1, _p2 = getImages( path.iloc[index].p1 , path.iloc[index].p2 )\n",
    "    p1.append(_p1);p2.append(_p2);Y.append(1)\n",
    "  indexes = np.random.choice( path[y==0].index, size=int(batch_size/2), replace=False )\n",
    "  for index in indexes:\n",
    "    _p1, _p2 = getImages( path.iloc[index].p1 , path.iloc[index].p2 )\n",
    "    p1.append(_p1);p2.append(_p2);Y.append(0)\n",
    "  return [np.array(p1),np.array(p2)], np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wihoOZsn73f4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def test_oneshot(model,N,verbose=0):\n",
    "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    inputs, targets = getMiniBatch(N, path = val, y = Y_val)\n",
    "    probs = model.predict(inputs)\n",
    "    auc = roc_auc_score( targets, probs, )\n",
    "    if verbose:\n",
    "        print(\"Got an AUC of {:.4f} in {} way one-shot learning.\".format(auc,N))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "SRD1pUAzDFDe",
    "outputId": "0f4350f8-0319-4dfc-df33-e8f88ff7a950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "vggface = VGGFace(model='resnet50', include_top=False, input_shape=IMG_DIM)\n",
    "vggface.trainable=False\n",
    "for layer in vggface.layers[:-3]:\n",
    "  layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YpZHLc4dHjVM"
   },
   "outputs": [],
   "source": [
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "  \n",
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "tleSY8ud8RGe",
    "outputId": "a4f3ab10-cc55-4306-8136-c1eda7b1412f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-0c3011879fd6>:12: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Lambda, Subtract\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "left_input = Input(IMG_DIM)\n",
    "right_input = Input(IMG_DIM)\n",
    "\n",
    "\n",
    "x1 = vggface(left_input)\n",
    "x2 = vggface(right_input)\n",
    "\n",
    "flatten = Flatten()\n",
    "x1 = flatten(x1)\n",
    "x2 = flatten(x2)\n",
    "\n",
    "fc = Dense(4096,activation='relu',kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias)\n",
    "\n",
    "encoded_l = fc(x1)\n",
    "encoded_r = fc(x2)\n",
    "\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(1e-3)\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy',auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Mi1Nm6G3GIHH"
   },
   "outputs": [],
   "source": [
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self): # Py3\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "          \n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "  \n",
    "  \n",
    "@threadsafe_generator\n",
    "def Generator(batch_size, path,y):\n",
    "  while True:\n",
    "    yield getMiniBatch(batch_size=batch_size,path=path, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5834
    },
    "colab_type": "code",
    "id": "kSM931f-Qnb6",
    "outputId": "c08dfa47-a507-4a0b-d8a1-ac796ed4319e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<__main__...., epochs=1000, validation_data=<__main__...., validation_steps=50, verbose=1, callbacks=[<keras.ca..., workers=4, steps_per_epoch=100)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 73s 726ms/step - loss: 3.0911 - acc: 0.5056 - auc: 0.5066 - val_loss: 2.4185 - val_acc: 0.4931 - val_auc: 0.4960\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 2.0042 - acc: 0.4984 - auc: 0.4962 - val_loss: 1.8431 - val_acc: 0.5062 - val_auc: 0.4966\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.7236 - acc: 0.5031 - auc: 0.4980 - val_loss: 1.6931 - val_acc: 0.4963 - val_auc: 0.4979\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.6707 - acc: 0.4937 - auc: 0.4983 - val_loss: 1.6087 - val_acc: 0.4994 - val_auc: 0.4984\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.6297 - acc: 0.4894 - auc: 0.4979 - val_loss: 1.6602 - val_acc: 0.4806 - val_auc: 0.4980\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.6289 - acc: 0.5006 - auc: 0.4976 - val_loss: 1.6099 - val_acc: 0.4906 - val_auc: 0.4977\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.6050 - acc: 0.5091 - auc: 0.4983 - val_loss: 1.5828 - val_acc: 0.4988 - val_auc: 0.4982\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.5738 - acc: 0.5091 - auc: 0.4982 - val_loss: 1.5721 - val_acc: 0.4850 - val_auc: 0.4980\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.5447 - acc: 0.5072 - auc: 0.4984 - val_loss: 1.5490 - val_acc: 0.4925 - val_auc: 0.4981\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.5088 - acc: 0.5112 - auc: 0.4982 - val_loss: 1.5066 - val_acc: 0.5025 - val_auc: 0.4986\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.5304 - acc: 0.4931 - auc: 0.4988 - val_loss: 1.5153 - val_acc: 0.4831 - val_auc: 0.4986\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.4657 - acc: 0.5091 - auc: 0.4984 - val_loss: 1.4550 - val_acc: 0.5075 - val_auc: 0.4989\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.4689 - acc: 0.5072 - auc: 0.4990 - val_loss: 1.4591 - val_acc: 0.5125 - val_auc: 0.4996\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.4680 - acc: 0.5041 - auc: 0.4999 - val_loss: 1.4715 - val_acc: 0.5269 - val_auc: 0.5004\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.4714 - acc: 0.5066 - auc: 0.5010 - val_loss: 1.4957 - val_acc: 0.4981 - val_auc: 0.5010\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.4574 - acc: 0.5022 - auc: 0.5011 - val_loss: 1.4630 - val_acc: 0.5169 - val_auc: 0.5014\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.5022 - acc: 0.5012 - auc: 0.5014 - val_loss: 1.5015 - val_acc: 0.5075 - val_auc: 0.5017\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.5097 - acc: 0.5044 - auc: 0.5016 - val_loss: 1.4522 - val_acc: 0.5131 - val_auc: 0.5017\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 1.4761 - acc: 0.4931 - auc: 0.5017 - val_loss: 1.4673 - val_acc: 0.4881 - val_auc: 0.5013\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 1.4587 - acc: 0.5009 - auc: 0.5012 - val_loss: 1.4822 - val_acc: 0.5012 - val_auc: 0.5013\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.4396 - acc: 0.4984 - auc: 0.5012 - val_loss: 1.4912 - val_acc: 0.4981 - val_auc: 0.5014\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.4501 - acc: 0.4997 - auc: 0.5008 - val_loss: 1.4435 - val_acc: 0.5150 - val_auc: 0.5009\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.4533 - acc: 0.4991 - auc: 0.5010 - val_loss: 1.4604 - val_acc: 0.5112 - val_auc: 0.5010\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.4810 - acc: 0.5041 - auc: 0.5012 - val_loss: 1.5795 - val_acc: 0.4925 - val_auc: 0.5011\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.5070 - acc: 0.4903 - auc: 0.5008 - val_loss: 1.4843 - val_acc: 0.5038 - val_auc: 0.5007\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.4814 - acc: 0.5062 - auc: 0.5005 - val_loss: 1.5099 - val_acc: 0.5006 - val_auc: 0.5004\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.5100 - acc: 0.5128 - auc: 0.5003 - val_loss: 1.4658 - val_acc: 0.4938 - val_auc: 0.5003\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.4954 - acc: 0.4934 - auc: 0.5002 - val_loss: 1.5881 - val_acc: 0.4963 - val_auc: 0.5001\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 1.4808 - acc: 0.5088 - auc: 0.5000 - val_loss: 1.5346 - val_acc: 0.5062 - val_auc: 0.5002\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.5212 - acc: 0.5031 - auc: 0.5003 - val_loss: 1.5232 - val_acc: 0.4950 - val_auc: 0.5002\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.5216 - acc: 0.5016 - auc: 0.5002 - val_loss: 1.5144 - val_acc: 0.5025 - val_auc: 0.5003\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.5460 - acc: 0.4906 - auc: 0.5001 - val_loss: 1.5771 - val_acc: 0.5075 - val_auc: 0.5000\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.5812 - acc: 0.4975 - auc: 0.4999 - val_loss: 1.6094 - val_acc: 0.4619 - val_auc: 0.4998\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.5656 - acc: 0.4916 - auc: 0.4996 - val_loss: 1.5376 - val_acc: 0.4994 - val_auc: 0.4995\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.5975 - acc: 0.4988 - auc: 0.4996 - val_loss: 1.6268 - val_acc: 0.5056 - val_auc: 0.4996\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.5875 - acc: 0.5044 - auc: 0.4997 - val_loss: 1.5905 - val_acc: 0.5056 - val_auc: 0.4998\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.5429 - acc: 0.5019 - auc: 0.4999 - val_loss: 1.5538 - val_acc: 0.5081 - val_auc: 0.5000\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.5656 - acc: 0.4953 - auc: 0.4999 - val_loss: 1.5740 - val_acc: 0.5075 - val_auc: 0.4999\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.5973 - acc: 0.4853 - auc: 0.4999 - val_loss: 1.6576 - val_acc: 0.5094 - val_auc: 0.4999\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.6572 - acc: 0.5031 - auc: 0.4999 - val_loss: 1.7242 - val_acc: 0.4875 - val_auc: 0.4999\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.7058 - acc: 0.4916 - auc: 0.4999 - val_loss: 1.7695 - val_acc: 0.4900 - val_auc: 0.5000\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.6919 - acc: 0.4966 - auc: 0.4998 - val_loss: 1.6879 - val_acc: 0.4906 - val_auc: 0.4998\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.5941 - acc: 0.5003 - auc: 0.4997 - val_loss: 1.5560 - val_acc: 0.4863 - val_auc: 0.4997\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.5129 - acc: 0.5122 - auc: 0.4998 - val_loss: 1.4793 - val_acc: 0.5212 - val_auc: 0.4998\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.4525 - acc: 0.5131 - auc: 0.4999 - val_loss: 1.4393 - val_acc: 0.4913 - val_auc: 0.5000\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.4081 - acc: 0.4991 - auc: 0.5001 - val_loss: 1.3934 - val_acc: 0.5106 - val_auc: 0.5001\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.3660 - acc: 0.4981 - auc: 0.5002 - val_loss: 1.3535 - val_acc: 0.4756 - val_auc: 0.5002\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.3275 - acc: 0.4956 - auc: 0.5001 - val_loss: 1.3150 - val_acc: 0.4900 - val_auc: 0.5001\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.2874 - acc: 0.4959 - auc: 0.5001 - val_loss: 1.2685 - val_acc: 0.5206 - val_auc: 0.5001\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.2517 - acc: 0.4909 - auc: 0.5001 - val_loss: 1.2419 - val_acc: 0.4875 - val_auc: 0.5001\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.2183 - acc: 0.4984 - auc: 0.5000 - val_loss: 1.1976 - val_acc: 0.5094 - val_auc: 0.5000\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.1837 - acc: 0.4916 - auc: 0.5000 - val_loss: 1.1695 - val_acc: 0.5050 - val_auc: 0.5000\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.1486 - acc: 0.5159 - auc: 0.5001 - val_loss: 1.1376 - val_acc: 0.5006 - val_auc: 0.5001\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.1222 - acc: 0.4966 - auc: 0.5001 - val_loss: 1.1147 - val_acc: 0.4894 - val_auc: 0.5001\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.0959 - acc: 0.4925 - auc: 0.5001 - val_loss: 1.0815 - val_acc: 0.4919 - val_auc: 0.5000\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.0657 - acc: 0.5081 - auc: 0.5001 - val_loss: 1.0541 - val_acc: 0.5188 - val_auc: 0.5001\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.0453 - acc: 0.4909 - auc: 0.5001 - val_loss: 1.0313 - val_acc: 0.5231 - val_auc: 0.5001\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 1.0206 - acc: 0.5022 - auc: 0.5001 - val_loss: 1.0112 - val_acc: 0.4988 - val_auc: 0.5001\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.9982 - acc: 0.4997 - auc: 0.5001 - val_loss: 0.9871 - val_acc: 0.4931 - val_auc: 0.5001\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.9778 - acc: 0.5041 - auc: 0.5001 - val_loss: 0.9700 - val_acc: 0.4956 - val_auc: 0.5001\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.9593 - acc: 0.4984 - auc: 0.5000 - val_loss: 0.9519 - val_acc: 0.4988 - val_auc: 0.5000\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.9401 - acc: 0.5109 - auc: 0.5000 - val_loss: 0.9342 - val_acc: 0.4963 - val_auc: 0.5000\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.9247 - acc: 0.4966 - auc: 0.5000 - val_loss: 0.9138 - val_acc: 0.5012 - val_auc: 0.5000\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.9070 - acc: 0.5006 - auc: 0.4999 - val_loss: 0.9076 - val_acc: 0.4763 - val_auc: 0.4999\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8939 - acc: 0.4919 - auc: 0.4999 - val_loss: 0.8842 - val_acc: 0.5025 - val_auc: 0.4999\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.8796 - acc: 0.4984 - auc: 0.4998 - val_loss: 0.8703 - val_acc: 0.5169 - val_auc: 0.4998\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.8676 - acc: 0.5144 - auc: 0.4999 - val_loss: 0.8664 - val_acc: 0.4925 - val_auc: 0.4999\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8543 - acc: 0.5178 - auc: 0.4999 - val_loss: 0.8560 - val_acc: 0.5050 - val_auc: 0.4999\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8486 - acc: 0.4891 - auc: 0.4999 - val_loss: 0.8404 - val_acc: 0.5075 - val_auc: 0.4999\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.8335 - acc: 0.5125 - auc: 0.4999 - val_loss: 0.8369 - val_acc: 0.4913 - val_auc: 0.5000\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.8281 - acc: 0.5078 - auc: 0.5000 - val_loss: 0.8216 - val_acc: 0.5069 - val_auc: 0.5000\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.8216 - acc: 0.4947 - auc: 0.5000 - val_loss: 0.8166 - val_acc: 0.5012 - val_auc: 0.5000\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8133 - acc: 0.5034 - auc: 0.5000 - val_loss: 0.8120 - val_acc: 0.4900 - val_auc: 0.5001\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8094 - acc: 0.4831 - auc: 0.5000 - val_loss: 0.8094 - val_acc: 0.4781 - val_auc: 0.5000\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.8002 - acc: 0.4966 - auc: 0.5000 - val_loss: 0.8001 - val_acc: 0.5056 - val_auc: 0.5000\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7965 - acc: 0.4934 - auc: 0.5000 - val_loss: 0.7973 - val_acc: 0.4875 - val_auc: 0.4999\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.7912 - acc: 0.4925 - auc: 0.4999 - val_loss: 0.7938 - val_acc: 0.5044 - val_auc: 0.4999\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.7866 - acc: 0.4856 - auc: 0.4998 - val_loss: 0.7840 - val_acc: 0.5062 - val_auc: 0.4998\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7813 - acc: 0.5016 - auc: 0.4998 - val_loss: 0.7815 - val_acc: 0.5056 - val_auc: 0.4998\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.7789 - acc: 0.4934 - auc: 0.4998 - val_loss: 0.7800 - val_acc: 0.4950 - val_auc: 0.4998\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.7758 - acc: 0.4934 - auc: 0.4998 - val_loss: 0.7716 - val_acc: 0.5150 - val_auc: 0.4998\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7719 - acc: 0.4956 - auc: 0.4998 - val_loss: 0.7707 - val_acc: 0.4975 - val_auc: 0.4997\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7669 - acc: 0.4997 - auc: 0.4997 - val_loss: 0.7680 - val_acc: 0.4775 - val_auc: 0.4997\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7629 - acc: 0.5225 - auc: 0.4997 - val_loss: 0.7658 - val_acc: 0.5181 - val_auc: 0.4998\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7664 - acc: 0.4894 - auc: 0.4998 - val_loss: 0.7595 - val_acc: 0.5112 - val_auc: 0.4997\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7603 - acc: 0.5125 - auc: 0.4998 - val_loss: 0.7628 - val_acc: 0.4838 - val_auc: 0.4998\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7567 - acc: 0.5012 - auc: 0.4998 - val_loss: 0.7623 - val_acc: 0.4931 - val_auc: 0.4999\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.7599 - acc: 0.5059 - auc: 0.4999 - val_loss: 0.7554 - val_acc: 0.5244 - val_auc: 0.4999\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7613 - acc: 0.4878 - auc: 0.5000 - val_loss: 0.7564 - val_acc: 0.5131 - val_auc: 0.4999\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7604 - acc: 0.4888 - auc: 0.4999 - val_loss: 0.7577 - val_acc: 0.4944 - val_auc: 0.4999\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.7571 - acc: 0.4937 - auc: 0.4998 - val_loss: 0.7568 - val_acc: 0.4838 - val_auc: 0.4998\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7535 - acc: 0.5034 - auc: 0.4998 - val_loss: 0.7544 - val_acc: 0.4963 - val_auc: 0.4998\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7539 - acc: 0.4894 - auc: 0.4998 - val_loss: 0.7559 - val_acc: 0.5062 - val_auc: 0.4998\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7552 - acc: 0.4925 - auc: 0.4998 - val_loss: 0.7527 - val_acc: 0.4756 - val_auc: 0.4997\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7547 - acc: 0.4866 - auc: 0.4997 - val_loss: 0.7516 - val_acc: 0.5025 - val_auc: 0.4997\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7501 - acc: 0.5044 - auc: 0.4997 - val_loss: 0.7509 - val_acc: 0.4888 - val_auc: 0.4996\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7517 - acc: 0.5000 - auc: 0.4996 - val_loss: 0.7465 - val_acc: 0.5175 - val_auc: 0.4997\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7485 - acc: 0.5125 - auc: 0.4997 - val_loss: 0.7483 - val_acc: 0.5194 - val_auc: 0.4997\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7501 - acc: 0.5019 - auc: 0.4997 - val_loss: 0.7476 - val_acc: 0.5144 - val_auc: 0.4997\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7497 - acc: 0.4972 - auc: 0.4997 - val_loss: 0.7540 - val_acc: 0.4713 - val_auc: 0.4997\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7475 - acc: 0.5047 - auc: 0.4997 - val_loss: 0.7538 - val_acc: 0.4975 - val_auc: 0.4997\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 71s 708ms/step - loss: 0.7454 - acc: 0.5138 - auc: 0.4997 - val_loss: 0.7512 - val_acc: 0.4888 - val_auc: 0.4998\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7498 - acc: 0.5059 - auc: 0.4997 - val_loss: 0.7474 - val_acc: 0.5081 - val_auc: 0.4997\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7483 - acc: 0.5000 - auc: 0.4997 - val_loss: 0.7485 - val_acc: 0.4988 - val_auc: 0.4997\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7487 - acc: 0.5053 - auc: 0.4998 - val_loss: 0.7488 - val_acc: 0.4919 - val_auc: 0.4998\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7480 - acc: 0.4947 - auc: 0.4997 - val_loss: 0.7496 - val_acc: 0.5056 - val_auc: 0.4997\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 0.7461 - acc: 0.5069 - auc: 0.4997 - val_loss: 0.7479 - val_acc: 0.4881 - val_auc: 0.4997\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 0.7467 - acc: 0.5037 - auc: 0.4997 - val_loss: 0.7494 - val_acc: 0.5138 - val_auc: 0.4997\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7483 - acc: 0.5006 - auc: 0.4997 - val_loss: 0.7451 - val_acc: 0.5150 - val_auc: 0.4997\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7472 - acc: 0.5012 - auc: 0.4997 - val_loss: 0.7436 - val_acc: 0.5181 - val_auc: 0.4997\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7445 - acc: 0.5081 - auc: 0.4998 - val_loss: 0.7485 - val_acc: 0.5000 - val_auc: 0.4998\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7468 - acc: 0.4872 - auc: 0.4998 - val_loss: 0.7490 - val_acc: 0.4894 - val_auc: 0.4997\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7461 - acc: 0.4934 - auc: 0.4997 - val_loss: 0.7514 - val_acc: 0.4863 - val_auc: 0.4997\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7461 - acc: 0.4947 - auc: 0.4997 - val_loss: 0.7448 - val_acc: 0.4863 - val_auc: 0.4996\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 0.7458 - acc: 0.4994 - auc: 0.4996 - val_loss: 0.7474 - val_acc: 0.4794 - val_auc: 0.4996\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7441 - acc: 0.5031 - auc: 0.4996 - val_loss: 0.7466 - val_acc: 0.5000 - val_auc: 0.4996\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.7443 - acc: 0.5025 - auc: 0.4996 - val_loss: 0.7507 - val_acc: 0.5000 - val_auc: 0.4996\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7446 - acc: 0.4975 - auc: 0.4996 - val_loss: 0.7445 - val_acc: 0.5050 - val_auc: 0.4996\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7416 - acc: 0.5109 - auc: 0.4996 - val_loss: 0.7487 - val_acc: 0.5012 - val_auc: 0.4996\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7444 - acc: 0.4931 - auc: 0.4996 - val_loss: 0.7433 - val_acc: 0.5131 - val_auc: 0.4996\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7429 - acc: 0.5031 - auc: 0.4996 - val_loss: 0.7444 - val_acc: 0.5012 - val_auc: 0.4996\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7436 - acc: 0.5091 - auc: 0.4996 - val_loss: 0.7491 - val_acc: 0.4794 - val_auc: 0.4996\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7446 - acc: 0.5059 - auc: 0.4996 - val_loss: 0.7453 - val_acc: 0.5044 - val_auc: 0.4996\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7426 - acc: 0.4972 - auc: 0.4996 - val_loss: 0.7486 - val_acc: 0.4875 - val_auc: 0.4996\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7443 - acc: 0.5006 - auc: 0.4996 - val_loss: 0.7467 - val_acc: 0.4875 - val_auc: 0.4996\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 0.7438 - acc: 0.4953 - auc: 0.4996 - val_loss: 0.7455 - val_acc: 0.4900 - val_auc: 0.4996\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7434 - acc: 0.5019 - auc: 0.4996 - val_loss: 0.7419 - val_acc: 0.5131 - val_auc: 0.4996\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7432 - acc: 0.4950 - auc: 0.4996 - val_loss: 0.7421 - val_acc: 0.5062 - val_auc: 0.4996\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7421 - acc: 0.5047 - auc: 0.4996 - val_loss: 0.7457 - val_acc: 0.5144 - val_auc: 0.4997\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7471 - acc: 0.4884 - auc: 0.4996 - val_loss: 0.7484 - val_acc: 0.4944 - val_auc: 0.4996\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7429 - acc: 0.5075 - auc: 0.4996 - val_loss: 0.7467 - val_acc: 0.4938 - val_auc: 0.4997\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7449 - acc: 0.5025 - auc: 0.4997 - val_loss: 0.7470 - val_acc: 0.5031 - val_auc: 0.4997\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7457 - acc: 0.4978 - auc: 0.4997 - val_loss: 0.7458 - val_acc: 0.5138 - val_auc: 0.4997\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7466 - acc: 0.4975 - auc: 0.4997 - val_loss: 0.7478 - val_acc: 0.4756 - val_auc: 0.4996\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7435 - acc: 0.5103 - auc: 0.4996 - val_loss: 0.7459 - val_acc: 0.4831 - val_auc: 0.4997\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.7445 - acc: 0.5016 - auc: 0.4996 - val_loss: 0.7429 - val_acc: 0.5019 - val_auc: 0.4996\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7448 - acc: 0.4975 - auc: 0.4996 - val_loss: 0.7446 - val_acc: 0.5106 - val_auc: 0.4996\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7446 - acc: 0.4956 - auc: 0.4996 - val_loss: 0.7418 - val_acc: 0.5094 - val_auc: 0.4996\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7422 - acc: 0.5041 - auc: 0.4996 - val_loss: 0.7482 - val_acc: 0.4894 - val_auc: 0.4996\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7457 - acc: 0.4900 - auc: 0.4996 - val_loss: 0.7488 - val_acc: 0.4975 - val_auc: 0.4996\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7438 - acc: 0.5012 - auc: 0.4996 - val_loss: 0.7435 - val_acc: 0.5119 - val_auc: 0.4996\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7426 - acc: 0.5050 - auc: 0.4996 - val_loss: 0.7430 - val_acc: 0.5200 - val_auc: 0.4996\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7452 - acc: 0.4888 - auc: 0.4996 - val_loss: 0.7439 - val_acc: 0.5181 - val_auc: 0.4996\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7451 - acc: 0.4928 - auc: 0.4996 - val_loss: 0.7445 - val_acc: 0.4850 - val_auc: 0.4996\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7432 - acc: 0.5016 - auc: 0.4996 - val_loss: 0.7408 - val_acc: 0.5012 - val_auc: 0.4996\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7430 - acc: 0.5072 - auc: 0.4996 - val_loss: 0.7453 - val_acc: 0.5044 - val_auc: 0.4996\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7437 - acc: 0.4838 - auc: 0.4996 - val_loss: 0.7434 - val_acc: 0.5069 - val_auc: 0.4996\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7426 - acc: 0.5109 - auc: 0.4996 - val_loss: 0.7450 - val_acc: 0.5031 - val_auc: 0.4996\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7445 - acc: 0.4903 - auc: 0.4996 - val_loss: 0.7504 - val_acc: 0.4813 - val_auc: 0.4996\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7425 - acc: 0.4988 - auc: 0.4996 - val_loss: 0.7480 - val_acc: 0.4950 - val_auc: 0.4996\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7435 - acc: 0.4978 - auc: 0.4996 - val_loss: 0.7438 - val_acc: 0.4919 - val_auc: 0.4996\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7432 - acc: 0.5091 - auc: 0.4996 - val_loss: 0.7485 - val_acc: 0.4769 - val_auc: 0.4996\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7444 - acc: 0.4906 - auc: 0.4995 - val_loss: 0.7467 - val_acc: 0.4906 - val_auc: 0.4995\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 71s 708ms/step - loss: 0.7447 - acc: 0.4978 - auc: 0.4995 - val_loss: 0.7418 - val_acc: 0.5119 - val_auc: 0.4995\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.7420 - acc: 0.5150 - auc: 0.4995 - val_loss: 0.7469 - val_acc: 0.4856 - val_auc: 0.4995\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7437 - acc: 0.5019 - auc: 0.4995 - val_loss: 0.7440 - val_acc: 0.5100 - val_auc: 0.4995\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.7422 - acc: 0.5106 - auc: 0.4995 - val_loss: 0.7425 - val_acc: 0.4981 - val_auc: 0.4995\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7433 - acc: 0.4972 - auc: 0.4995 - val_loss: 0.7409 - val_acc: 0.5112 - val_auc: 0.4995\n",
      "Epoch 159/1000\n",
      " 60/100 [=================>............] - ETA: 18s - loss: 0.7425 - acc: 0.4906 - auc: 0.4995"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4c202002ab37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m siamese_net.fit_generator( train_gen, samples_per_epoch=100, epochs=1000, \n\u001b[1;32m     13\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                           verbose=1,callbacks=callbacks_list, workers=4)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import threading\n",
    "\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss',mode='max',patience=20,min_lr=1e-5,verbose=1)\n",
    "\n",
    "callbacks_list = [reducelr]\n",
    "\n",
    "\n",
    "train_gen = Generator(batch_size=32,path=train,y=Y_train)\n",
    "val_gen = Generator(batch_size=32,path=val,y=Y_val)\n",
    "\n",
    "siamese_net.fit_generator( train_gen, samples_per_epoch=100, epochs=1000, \n",
    "                          validation_data=val_gen, validation_steps=50, \n",
    "                          verbose=1,callbacks=callbacks_list, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6Z4qkn3wPmyO"
   },
   "outputs": [],
   "source": [
    "siamese_net.save_weights('siamesenet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xEKM9urnP-Xn"
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights('siamesenet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YtMnPBFYODGm",
    "outputId": "93a94448-c437-4c46-919a-3c40bbcbc253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del allPhotos; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "pMD1iAphODDk",
    "outputId": "4399a571-9787-4884-f8ae-1160a394b22d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5310, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_pair</th>\n",
       "      <th>is_related</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face05508.jpg-face01210.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>test/face05508.jpg</td>\n",
       "      <td>test/face01210.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face05750.jpg-face00898.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>test/face05750.jpg</td>\n",
       "      <td>test/face00898.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face05820.jpg-face03938.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>test/face05820.jpg</td>\n",
       "      <td>test/face03938.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face02104.jpg-face01172.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>test/face02104.jpg</td>\n",
       "      <td>test/face01172.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face02428.jpg-face05611.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>test/face02428.jpg</td>\n",
       "      <td>test/face05611.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img_pair  ...                  p2\n",
       "0  face05508.jpg-face01210.jpg  ...  test/face01210.jpg\n",
       "1  face05750.jpg-face00898.jpg  ...  test/face00898.jpg\n",
       "2  face05820.jpg-face03938.jpg  ...  test/face03938.jpg\n",
       "3  face02104.jpg-face01172.jpg  ...  test/face01172.jpg\n",
       "4  face02428.jpg-face05611.jpg  ...  test/face05611.jpg\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['p1'] = submission.img_pair.apply( lambda x: 'test/'+x.split('-')[0] )\n",
    "submission['p2'] = submission.img_pair.apply( lambda x: 'test/'+x.split('-')[1] )\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dmBQTMX6UVPd",
    "outputId": "5267a8fb-c70c-4d0c-de3e-e81453ef39fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:53<00:00, 23.57s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "probs = []\n",
    "for i,j in tqdm([ (0,1000),(1000,2000),(2000,3000),(3000,4000),(4000,5310) ]):\n",
    "  imgs1 = np.array( [ read_img(photo) for photo in submission.p1.values[i:j] ] )\n",
    "  imgs2 = np.array( [ read_img(photo) for photo in submission.p2.values[i:j] ] )\n",
    "  prob =  siamese_net.predict( [ imgs1, imgs2 ] )\n",
    "  probs.append(np.squeeze(prob))\n",
    "  del imgs1,imgs2; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "26g7HCzrWJUA"
   },
   "outputs": [],
   "source": [
    "submission.is_related = np.concatenate(probs)\n",
    "submission.drop( ['p1','p2'],axis=1,inplace=True )\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "93Cw8sgPWzSz"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "PwtaujPKOCuY",
    "outputId": "49d9c43b-4f47-4808-8f95-61dc2abad575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "100% 199k/199k [00:05<00:00, 35.0kB/s]\n",
      "Successfully submitted to Northeastern SMILE Lab - Recognizing Faces in the Wild"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c recognizing-faces-in-the-wild -f submission.csv -m \"1st prob vgg-face basic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "_NVRczUVODpp",
    "outputId": "67e84a27-3f0a-4b9b-8ac2-0a90b4f440c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.input_layer.InputLayer object at...</td>\n",
       "      <td>input_3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv1_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv1_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>pool1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv2_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv2_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>pool2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv3_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv3_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv3_3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>pool3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv4_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv4_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv4_3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>pool4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv5_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv5_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv5_3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>pool5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Layer Type  ... Layer Trainable\n",
       "0   <keras.engine.input_layer.InputLayer object at...  ...           False\n",
       "1   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "2   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "3   <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "4   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "5   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "6   <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "7   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "8   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "9   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "10  <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "11  <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "12  <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "13  <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "14  <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "15  <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "16  <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "17  <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "18  <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "\n",
       "[19 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vggface.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "c5suS6O_RmC5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Recognizing Faces in The Wild.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
